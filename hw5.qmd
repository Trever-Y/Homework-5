---
title: "Model Comparison"
author: "Trever Yoder"
format: pdf
editor: visual
---

## Task 1: Conceptual Questions

-   **What is the purpose of using cross-validation when fitting a random forest model?**

    Cross‑validation is used to estimate how well the random forest will perform on unseen data by repeatedly splitting the data into “folds,” training on some folds and validating on the others. This helps guard against overfitting and provides a more reliable measure of out‑of‑sample predictive accuracy.

-   **Describe the bagged tree algorithm.**

    Bagged trees (bootstrap aggregating) build many decision trees on different bootstrap samples of the training data and then average (for regression) or majority‑vote (for classification) their predictions. By aggregating across models trained on varied subsets, bagging reduces variance and improves stability compared to a single decision tree.

-   **What is meant by a general linear model?**

    A general linear model (GLM) expresses a continuous response variable (Y) as a linear combination of predictors: \[ Y = \beta\_0 + \beta\_1 X_1 + \cdots + \beta\_p X_p + \varepsilon, \] where (\varepsilon) is assumed to be normally distributed with constant variance. It encompasses methods like ANOVA, ANCOVA, and multiple linear regression.

-   **When fitting a multiple linear regression model, what does adding an interaction term do? That is, what does it allow the model to do differently as compared to when it is not included in the model?**

    An interaction term (e.g., (X_1 \times X_2)) allows the effect of one predictor on the response to change depending on the level of the other predictor. Without interactions the model assumes additive effects; with interactions it can capture non‑additive relationships, where the slope for (X_1) varies by the value of (X_2).

-   **Why do we split our data into a training and test set?**

    Splitting data ensures that we can train the model on one subset (training set) and then evaluate its performance on completely unseen data (test set). This provides an unbiased assessment of how well the model generalizes to new observations and helps detect overfitting.

## Task 2: Data Prep

### Packages and Data

```{r load-packages, message=false, warning=false}
library(tidyverse)
library(tidymodels)
library(caret)
library(yardstick)

Heart_data <- read_csv(
  "heart.csv") 
summary(Heart_data)
```

### 1

Heart Disease is treated as a quantitative variable which does not make sense. Conceptually, Heart Disease is a categorical variable since 0 means no heart disease and 1 means presence of heart disease. A decimal like 0.5 wouldn't fall into either category. A person either has or does not have heart disease (1 or 0).

### 2

```{r}
new_heart <- Heart_data %>%
  mutate(Heart_Disease = factor(HeartDisease, levels = c(0, 1), labels = c("No", "Yes"))) %>%
  select(-ST_Slope, -HeartDisease)
```

## Task 3: EDA

### 1. Plot to check for interaction

```{r}
ggplot(new_heart, aes(x = MaxHR, y = Age, color = Heart_Disease)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  scale_color_viridis_d(option = "D") +
  labs(
    title = "Age vs Max Heart Rate by Heart Disease Status",
    x = "Max Heart Rate",
    y = "Age",
    color = "Heart Disease"
  ) +
  theme_minimal()
```

### 2. Conclusion based on visual evidence

We can see that the slopes are different. An additive model would assume their slopes to be the same. Therefore, to account for different slopes, we need to use an interaction model.

